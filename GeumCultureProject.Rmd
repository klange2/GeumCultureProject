---
title: "R Notebook"
output: html_notebook
---
---
title: "GeumCultureProject"
author: "Kacey Lange"
date: "2024-07-17"
output: html_document
---
# Libraries ---
  
followed instructions: https://github.com/bioc/sangeranalyseR

``` {r}
#library(ggplot2)
library(readxl)
library(tidyverse)
library(googlesheets4)
library(dplyr)
library(tidyr)
library(broom)
library(purrr)
#library(vegan)
library(RColorBrewer)
library(forcats)
#library(boxr)
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

# The following initializes usage of Bioc devel
BiocManager::install(version='devel')

BiocManager::install("sangeranalyseR")
install.packages("devtools")


library(devtools)

## Install the release version
install_github("roblanf/sangeranalyseR", ref = "master")

## Install the development version
install_github("roblanf/sangeranalyseR", ref = "develop")
install.packages("GenomeInfoDbData")
library(sangeranalyseR) #go to GitHub for TMZ file or
#install(BiocManager)
library(sangerseqR)
#library(Biostrings)
#library(ggtree)
library(viridisLite)
#library(treeio)
#library(geiger)
library(ape)
#library(ggnewscale)
library(phytools)

#devtools::install_github("brendanf/FUNGuildR")

#library(FUNGuildR)


library(remotes)
library(ape)

#BiocManager::install("ggtree")


library(picante)
library(phyloseq)
library(nlme)
#library(FUNGuildR)

#BiocManager::install("dada2")
library(dada2)

```

# Sanger Sequencing data ---

Following is for documention. If you need to work with alignments,
McKenzie recommends using the "contigs_object.RData" file on GDrive. You
need to use `sangeranalyseR` package in order to work with it.

load("C:/Users/Kacey/Documents/R/Projects/Culture/contigs_object.RData")

Genewiz seq data folder id (ancestor folder id): 112149094632

#there are two different naming conventions for ab1 files for some reason (anas vs mine)
``` {r}
names <- as.vector(list.files('C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/Trace/Pass'))

str_replace_all(names,'1F','F1') %>%
  as.vector() -> replace

setwd("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/Trace/Pass")
file.rename(from = names, to=replace)
```

## Align sequences and write to FASTA ---

Sangeranalyser defaults to Mott (M1 method) Phred quality cutoff = 30
(.001 on a log scale). default to 2 reads necessary to build contig
(i.e. F+R); 20 is default min length of read after trimming; Mott was
bad b/c we have a lot of random low quality bases interspersed.

*Used trimmomatic algorithm for sliding window (instead of Mott)* so
that a single low quality base doesnt terminate sequence too early.
this is a common problem in this data set.

also tried using reference amino acid sequence, but performed much worse
than normal alignment process consensus amino based on M2 cutoff = 30,
sliding window =10
"FFLLSSSSYY\*\*CC\*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG"

This generates a new FASTA:

```{r, eval=FALSE}
contigs <- SangerAlignment(ABIF_Directory     = "C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/Trace/Pass",
                          inputSource         = "ABIF",
                          processMethod       = "REGEX",
                          REGEX_SuffixForward = "-ITSF1.ab1$",
                          REGEX_SuffixReverse = "-LR3.ab1$",
                         TrimmingMethod       = "M1",
                         M1TrimmingCutoff     = 1e-04,
                         M2CutoffQualityScore = NULL,
                         M2SlidingWindowSize  = NULL)
  
#contigs <- updateQualityParam(contigs,
                              #TrimmingMethod = "M2",
                              #M2CutoffQualityScore = 30,
                              #M2SlidingWindowSize  = 10)

writeFastaSA(contigs,
             outputDir         = "C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/FASTAS",
             compress          = FALSE,
             selection         = "contigs_unalignment")

launchApp(contigs)

```

## T-BAS ---

take output FASTA (unaligned) and pass through NCSU ITSx to separate
various loci of interest (should be ITS1, 5.8S, ITS2, some of LSU)

Retain all metadata for OTU members

ITS locus is included (first FASTA) - filter unknowns to selected taxon and generate UNITE report

Run RDP with UNITE (ITS), FunGuild, and NCBI WWW bastn

McKenzie:
think I want to classify using Warcup b/c it seems to perform better athigher resolution taxon assignments 
(there is a citation for this somewhere)

probably don't cluster on only one locus bc that would be dumb/probably
actually skip clustering altogether bc we want info for each isolate

Create OTU fasta files

McKenzie:
definitely don't do de novo tree construction, use Evolutionary placement algorithm (bc that will incorporate extant info from TBAS which is the whole point); Emily used de novo though?
EPA and EPA ng are very similar, basically differ in computing
efficiency.

Me:
RAxML with de novo tree construction

McKenzie:
3/8/23 don't use RDP classifier b/c they only consider LSU and I don't
think we actually have enough LSU coverage to solely depend on that

*use result files from run 6V3PIQ4N. This is good one.*


```{r}
geumroot <- read.csv("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archiveM76GMYAB_/assignments_report_addvoucherM76GMYAB.csv")

colnames(geumroot)[16]<- "otu"
colnames(geumroot)[1]<- "Query.sequence"
```

# Phylogenetic Analysis

Import TBAS tree, remove outgroup taxa, rename tips to reflect *OTU IDs
I've been using* since 2020

```{r}
#newtree <- read.tree("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archiveM76GMYAB_/M76GMYAB.nwk")

trimmednwk <-read.tree("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archiveSAGGBM55_/SAGGBM55.nwk")

# tree with species names 
#trimmednwk$tip.label <- geumroot[[12]][match(trimmednwk$tip.label, geumroot[[1]])]
#taxtree <- ggtree(trimmednwk)+geom_tiplab(size=1)
#ggsave('C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/taxtree.pdf')

# tree with OTUs 
trimmednwk$tip.label <- geumroot[[16]][match(trimmednwk$tip.label, geumroot[[1]])]
#trimmednwk <- ggtree(trimmednwk)+geom_tiplab(size=1)
#ggsave('C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/otutree.pdf')
```

# Visualize Trait Data on tree

Ultimate goal is single tree that has collection and trait information

Phytools also has some visualization tools but McKenzie prefers ggtree
bc it's built on ggplot which you probably already know

Need to add different types of variables (traits) separately, since they
take unique aesthetic mapping regimes

``` {r}
library(ggtree)

geumroot <- geumroot %>% select(otu, everything())
kind of weird syntax, but this is how you bind data to tree^

plot <- ggtree(finaltree, branch.length = "none") #%<+% relocate(geumroot, otu, .before = Query.sequence)

plot+geom_label(aes(label=Most.common.order.level.assignment, size=5))+
  geom_tippoint(aes(color=Guild))+
  geom_tiplab(offset=5)+
  theme(legend.position = "none")
  
  plot+geom_tippoint(aes(color = color, size=10))+geom_tiplab(offset=.1, size=2)
  +labs(title = "Origin Site") 
  +theme(text = element_text(size = 30))
  + guides(colour = guide_legend(override.aes = list(size=10)))
```

# Reading in data

There are multiple OTUs for one species, so this is to clean it up

##### T-BAS data

OTUold is the otu name that was input for the isolate name in T-BAS, every isolate has a unique OTUold. The numbers of OTUold are from Nelle's original T-BAS run and then we added A, B C, etc to them to make them unique.
Query.sequence is also unique to each isolate. it is the OTUold plus the species name that Nelle's original T-BAS run came up with
OTU is the new analysis OTU - what I want
I think I want "Genusspecies" as for the taxonomy. "taxon assignment" is similar to genusspecies but sometimes has multiple taxa listed
anything with CERVNAZT is from the input data (so from Nelle's data), not what I want
Kacey's data = RKLYQOAK

##### Culture data

Culture IDs are unique to the sequence
Query.sequence 14,2,3,4 did not have an ITS region, remove 

```{r}
culture <- read_sheet("https://docs.google.com/spreadsheets/d/1Ys3msUUPmmOo1NeRqHfsdhJzU_mEwBOytZe6AmAribQ/edit?gid=0#gid=0", sheet = "Sheet1", na='NULL')

culture2<-culture%>%
  dplyr::select(Query.sequence,...3)%>%
  rename(PlantIndividual=...3)%>%
  separate(PlantIndividual, 
           into = c("Community", "PlantIndividual"), 
           sep = "(?<=[A-Za-z])(?=[0-9])"
           )
head(culture2)

geumroot2<-geumroot%>%
  filter(is.na(`otu`)==F,Query.sequence!="14",Query.sequence!="2",Query.sequence!="3",Query.sequence!="4",,Query.sequence!="5")%>%
  unite(CultureID,otu,Taxon.assignment,remove=F)%>%
  dplyr::select(Query.sequence,CultureID,Community_Type_M76GMYAB,Site_M76GMYAB,Latitude_M76GMYAB,Longitude_M76GMYAB,otu,Trophic.Mode,Guild,Taxon.assignment,GenusSpecies)%>%
  rename(Community=Community_Type_M76GMYAB,Site=Site_M76GMYAB,Lat=Latitude_M76GMYAB,Long=Longitude_M76GMYAB)%>%
mutate(Community = factor(Community, levels = c("DM", "SB", "FF", "MM")),Site = factor(Site, levels = c("P", "Q")))
head(geumroot2)

length(geumroot2$CultureID)

dat<-full_join(geumroot2,culture2,by="Query.sequence")%>%
  filter(is.na(otu)==F)
head(dat)
dim(dat)

#Collapse identical OTUs into one row. Looking at abundances of OTUs in the whole dataset. there are many many 1's (singletons). also this is needed to create the community dataset below
dat2<-dat%>%
  group_by(Community.x,Site,PlantIndividual,otu)%>%
  summarise(abundance=n())
as.data.frame(dat2)
data.frame(dat2$Community.x,dat2$Site,dat2$PlantIndividual,dat2$otu,dat2$abundance)

#make wide
dat3<-dat2%>%
  ungroup()%>%
  unite(CommunitySitePL,Community.x,Site,PlantIndividual,remove=F)%>%
  spread(otu,abundance,fill=0)
dat.comm<-data.frame(dat3[,5:60])
row.names(dat.comm)<-dat3$CommunitySitePL

```

##### Phylogenetic tree
note - the uncleaned tree in this directory contains the genus species names attached to the OTU numbers

```{r}

trimmednwk <-read.tree("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archiveSAGGBM55_/SAGGBM55.nwk")

# tree with OTUs 
trimmednwk$tip.label <- geumroot[[16]][match(trimmednwk$tip.label, geumroot[[1]])]

plot(trimmednwk)

```


##### Faith's Phylogenetic distance

```{r}

PD<-pd(dat.comm,trimmednwk)

dat4<-data.frame(dat3[,1:4],PD,dat3[,5:60])
```

##### MPD by plantindividual

```{r}
phydist <- cophenetic(trimmednwk)
ses.mpd.result.notweighted <- ses.mpd(dat.comm, phydist, null.model="taxa.labels",abundance.weighted=FALSE, runs=999) #takes 5 min with 999
ses.mpd.result.notweighted
ses.mpd.result.notweighted$CommunitySitePL<-rownames(ses.mpd.result.notweighted)
ses.mpd.result.notweighted1<-ses.mpd.result.notweighted%>%
  select(CommunitySitePL,mpd.obs.z)%>%
  rename(mpd.obs.z.notweighted=mpd.obs.z)

ses.mpd.result.weighted <- ses.mpd(dat.comm, phydist, null.model="taxa.labels",abundance.weighted=TRUE, runs=999) #takes 5 min with 999
ses.mpd.result.weighted
ses.mpd.result.weighted$CommunitySitePL<-rownames(ses.mpd.result.weighted)
ses.mpd.result.weighted1<-ses.mpd.result.weighted%>%
  select(CommunitySitePL,mpd.obs.z)%>%
  rename(mpd.obs.z.weighted=mpd.obs.z)

dat5<-dat4%>%
  full_join(ses.mpd.result.notweighted1)%>%
  full_join(ses.mpd.result.weighted1)
  
  
dat6<-data.frame(dat5[,1:6],dat5[,63:64],dat5[,7:62])
head(dat6)

```

##### phyloseq object

```{r}
otus<-dat6[,9:64]
otus2<-t(otus)
sampleotus<-dat6[,c(1:8)]
taxonomyotus<-as.matrix(data.frame(Kingdom=row.names(otus2),Phylum=row.names(otus2),Class=row.names(otus2),Order=row.names(otus2),Class=row.names(otus2),Family=row.names(otus2),Genus=row.names(otus2),Species=row.names(otus2)))
rownames(taxonomyotus)<-row.names(otus2)

datp <- merge_phyloseq(otu_table(otus2,taxa_are_rows = T), tax_table(taxonomyotus), sample_data(sampleotus),trimmednwk)

#calculate unifrac distances
unifracp<-unifrac(otus,trimmednwk)
```

#### Summary of files

```{r}
datp #phyloseq object
head(dat6) #big data frame, wide data format, dat3 plus PD and MPD data
dat7 #dat6 plus funguild pathogens/symbiotrophs
dat2 #long dataformat 
```

###### testing blasting to unite
unite.ref <- "/Users/farrer/Dropbox/EmilyComputerBackup/Documents/LAMarsh/Survey/Stats/Gradient/QIIME2/sh_general_release_dynamic_s_04.02.2020.fasta" 

taxaonly2 <- read.csv("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/taxaonly.csv")

```{r}
unite.ref <- "C:/Users/Kacey/Documents/Tulane/Lab/Culture/UNITE/sh_general_release_dynamic_s_04.04.2024.fasta"


#I got this data from assignments_report_nodups6V3PIQ4N
myotus<-read.csv("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archiveM76GMYAB_/assignments_report_nodupsM76GMYAB.csv",header=T);rownames(myotus)<-myotus$abundance

myotus2 <- myotus[,c(21,16)]
names(myotus2)[names(myotus2) == 'ITS'] <- 'sequence'
names(myotus2)[names(myotus2) == 'otu'] <- 'abundance'

taxa<-assignTaxonomy(myotus2, unite.ref, multithread = TRUE, minBoot=70, tryRC = TRUE,outputBootstraps=T) #was minBoot=70
taxaonly<-data.frame(taxa$tax);rownames(taxaonly)<-1:dim(taxa$tax)[1]
taxaboot<-data.frame(taxa$boot);rownames(taxaboot)<-1:dim(taxa$tax)[1]
taxaonly
taxaboot
rownames(taxaonly)<-rownames(myotus)
genusspecies<-data.frame(otu=rownames(myotus),genusspecies=paste(gsub("^.*?__","",taxaonly[,"Genus"]),gsub("^.*?__","",taxaonly[,"Species"])),genusboot=taxaboot[,"Genus"],speciesboot=taxaboot[,"Species"])

sort(unique(genusspecies$genusspecies))
sort(unique(taxaonly$Phylum))

taxaonly%>%group_by(Phylum)%>%tally()
```

##### FunGuild

The weird thing about FUNGuildR is that for some taxa, like when I have Fusarium equiseti it matches to Nectriaceae rather than Fusarium in the database. When I used the FUNGUILD in the terminal, it worked better and matched to the lowest taxonomic level. 

using FUNGuildR

```{r}
# genussp<-paste(gsub("^.*?__","",taxaonly$Genus),gsub("^.*?__","",taxaonly$Species))
# taxaonly$Taxonomy<-paste(gsub("^.*?__","",taxaonly$Kingdom),gsub("^.*?__","",taxaonly$Phylum),gsub("^.*?__","",taxaonly$Class),gsub("^.*?__","",taxaonly$Order),gsub("^.*?__","",taxaonly$Family),gsub("^.*?__","",taxaonly$Genus),genussp,sep=";")

#Download the up-to-date database
#fung <- get_funguild_db()

#save it to my computer for reproducable data
#saveRDS(fung, "funguild.rds")

#load it back into workspace
#fung <- loadRDS("funguild.rds")

# fung_guilds <- funguild_assign(taxaonly, db = fung)

#temp3 <- funguild_query("Buergenerula*", "taxon", db = fung)


#Doing it in terminal - use this
taxaonly2<-taxaonly
taxaonly2$taxonomy<-paste(taxaonly2$Kingdom,taxaonly2$Phylum,taxaonly2$Class,taxaonly2$Order,taxaonly2$Family,taxaonly2$Genus,taxaonly2$Species,sep=";")

write.csv(taxaonly2,"C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/taxaonly.csv")

#open the file, make the first column name OTU ID, save as a .txt file (add the .txt extension). then run below:

python FUNGuild.py taxa -otu taxaonly.txt -format tsv -column taxonomy -classifier unite
python FUNGuild.py guild -taxa taxaonly.taxa.txt         

guilds<-read.delim("/Users/farrer/Dropbox/EmilyComputerBackup/Documents/LAmarsh/Culturing/FiguresStats/LAmarshCulture/FUNGuild/taxaonly.taxa.guilds.txt")
View(guilds)

guilds%>%filter(trophicMode==("Pathotroph"))
guilds%>%filter(trophicMode==("Symbiotroph"))

View(funguild_query("*Saprotroph*", "trophicMode", db = guilds))

#merge with OTU table (of datp) with guilds from above
otutomerge<-data.frame(otu_table(datp))
otutomerge$OTU<-rownames(otutomerge)
head(guilds)
guilds2<-guilds%>%
  full_join(otutomerge)
head(guilds2)
ind<-which(guilds2$guild=="Plant Pathogen")
plantpathogen<-colSums(guilds2[ind,18:89])
plantpathogentaxa<-colSums(guilds2[ind,18:89]>0)

ind<-funguild_query("*Plant Pathogen*", "guild", db = guilds2)$OTU#trophicMode
ind2<-which(guilds2$OTU%in%ind)
plantpathogenbroad<-colSums(guilds2[ind2,18:89])
plantpathogenbroadtaxa<-colSums(guilds2[ind2,18:89]>0)

ind<-funguild_query("*Plant Pathogen*", "guild", db = guilds2)#trophicMode
ind2<-ind[which(ind$confidenceRanking%in%c("Probable","Highly Probable")),"OTU"]
ind3<-which(guilds2$OTU%in%ind2)
plantpathogenbroadprobablehp<-colSums(guilds2[ind3,18:89])
plantpathogenbroadprobablehptaxa<-colSums(guilds2[ind3,18:89]>0)

ind<-funguild_query("*Symbiotroph*", "trophicMode", db = guilds2)$OTU
ind2<-which(guilds2$OTU%in%ind)
symbiotroph<-colSums(guilds2[ind2,18:89])
symbiotrophtaxa<-colSums(guilds2[ind2,18:89]>0)

ind<-funguild_query("*Symbiotroph*", "trophicMode", db = guilds2)
ind2<-ind[which(ind$confidenceRanking%in%c("Probable","Highly Probable")),"OTU"]
ind3<-which(guilds2$OTU%in%ind2)
symbiotrophprobablehp<-colSums(guilds2[ind3,18:89])
symbiotrophprobablehptaxa<-colSums(guilds2[ind3,18:89]>0)

totalabundance<-colSums(guilds2[,18:89])

temp<-data.frame(sample_data(datp))
temp$rownames<-rownames(temp)
temp<-temp%>%
  dplyr::select(rownames,PlantIndividualYear)
temp2<-data.frame(temp,plantpathogen,plantpathogenbroad,plantpathogenbroadprobablehp,symbiotroph,symbiotrophprobablehp,totalabundance,plantpathogentaxa,plantpathogenbroadtaxa,plantpathogenbroadprobablehptaxa,symbiotrophtaxa,symbiotrophprobablehptaxa)

dat7<-dat6%>%
  full_join(temp2)

phragspartina<-dat6%>%
  filter(HostPlant%in%c('Phragmites australis','Spartina patens'))
phragspartina<-dat7%>%
  filter(HostPlant%in%c('P. australis','S. patens'))
```

##### git hub token stuff

```{r}
install.packages("gitcreds")
library(gitcreds)
gitcreds_set()
 #first when it asks to enter password or token I put my computer password
 #then do gitcreds_set() again and select 2, then paste my token
#Note: use usename (email) and token, when RStudio wants the github password
```