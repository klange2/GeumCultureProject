---
title: "R Notebook"
output: html_notebook
---
---
title: "GeumCultureProject"
author: "Kacey Lange"
date: "2024-07-17"
output: html_document
---
# Libraries
  
followed instructions: https://github.com/bioc/sangeranalyseR

github acces token: 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li

``` {r}
#library(ggplot2)
library(readxl)
library(tidyverse)
library(googlesheets4)
library(dplyr)
library(tidyr)
library(broom)
library(purrr)
#library(vegan)
library(RColorBrewer)
library(forcats)
#library(boxr)
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")

# The following initializes usage of Bioc devel
BiocManager::install(version='devel')

BiocManager::install("sangeranalyseR")
install.packages("devtools")


library(devtools)

## Install the release version
install_github("roblanf/sangeranalyseR", ref = "master")

## Install the development version
install_github("roblanf/sangeranalyseR", ref = "develop")
install.packages("GenomeInfoDbData")
library(sangeranalyseR) #go to GitHub for TMZ file or
#install(BiocManager)
library(sangerseqR)
#library(Biostrings)
#library(ggtree)
library(viridisLite)
#library(treeio)
#library(geiger)
library(ape)
#library(ggnewscale)
library(phytools)

#devtools::install_github("brendanf/FUNGuildR")

#library(FUNGuildR)


library(remotes)
library(ape)

#BiocManager::install("ggtree")


library(picante)
library(phyloseq)
library(nlme)
#library(FUNGuildR)

#BiocManager::install("dada2")
library(dada2)

```

# Sanger Sequencing data ---

Following is for documention. If you need to work with alignments,
McKenzie recommends using the "contigs_object.RData" file on GDrive. You
need to use `sangeranalyseR` package in order to work with it.

load("C:/Users/Kacey/Documents/R/Projects/Culture/contigs_object.RData")

Genewiz seq data folder id (ancestor folder id): 112149094632

## there are two different naming conventions for ab1 files for some reason (anas vs mine)
``` {r}
names <- as.vector(list.files('C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/Trace/Pass'))

str_replace_all(names,'1F','F1') %>%
  as.vector() -> replace

setwd("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/Trace/Pass")
file.rename(from = names, to=replace)
```

## Align sequences and write to FASTA ---

McKenzie:
Sangeranalyser defaults to Mott (M1 method) Phred quality cutoff = 30(.001 on a log scale). default to 2 reads necessary to build contig(i.e. F+R); 20 is default min length of read after trimming; Mott wasbad b/c we have a lot of random low quality bases interspersed.
*Used trimmomatic algorithm for sliding window (instead of Mott)* so that a single low quality base doesnt terminate sequence too early.this is a common problem in this data set.
also tried using reference amino acid sequence, but performed much worsethan normal alignment process consensus amino based on M2 cutoff = 30,sliding window =10
"FFLLSSSSYY\*\*CC\*WLLLLPPPPHHQQRRRRIIIMTTTTNNKKSSRRVVVVAAAADDEEGGGG"

Emily:
The M2 method was bad because there was a lot of uncalled basepairs (i.e W,K,Y,...). With the M1 method, there were much less uncalled basepairs. Use trimming cutoff of 1e-04

Kacey:
Emily was right and the M1 method was better. There was 45 OTUs with M2 and 56 with M1. I will continue with using M1.To properly make contigs, the samples have to have the same amount of characters. For example, I had to change sample 1-ITSF1.ab1 to 001-ITSF1.ab1 because I have samples with three characters (250-ITSF1.ab1). Without making them the same amount of characters, it will read multiple samples under 1 contig. I don't know if this changes teh data or not?

This generates a new FASTA:

```{r, eval=FALSE}
contigs <- SangerAlignment(ABIF_Directory     = "C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/Trace/Pass",
                          inputSource         = "ABIF",
                          processMethod       = "REGEX",
                          REGEX_SuffixForward = "-ITSF1.ab1$",
                          REGEX_SuffixReverse = "-LR3.ab1$",
                         TrimmingMethod       = "M1",
                         M1TrimmingCutoff     = 1e-04,
                         M2CutoffQualityScore = NULL,
                         M2SlidingWindowSize  = NULL)
  
#contigs <- updateQualityParam(contigs,
                              #TrimmingMethod = "M2",
                              #M2CutoffQualityScore = 30,
                              #M2SlidingWindowSize  = 10)

writeFastaSA(contigs,
             outputDir         = "C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/Data/FASTAS",
             compress          = FALSE,
             selection         = "contigs_unalignment")

launchApp(contigs)

```

# T-BAS

Mckenzie:
-take output FASTA (unaligned) and pass through NCSU ITSx to separate various loci of interest (should be ITS1, 5.8S, ITS2, some of LSU)
-Retain all metadata for OTU members
-ITS locus is included (first FASTA) - filter unknowns to selected taxon and generate UNITE report
-Run RDP with UNITE (ITS), FunGuild, and NCBI WWW bastn
-think I want to classify using Warcup b/c it seems to perform better athigher resolution taxon assignments 
(there is a citation for this somewhere)
-probably don't cluster on only one locus bc that would be dumb/probably
-actually skip clustering altogether bc we want info for each isolate
-Create OTU fasta files
-definitely don't do de novo tree construction, use Evolutionary placement algorithm (bc that will incorporate extant info from TBAS which is the whole point); Emily used de novo though?
EPA and EPA ng are very similar, basically differ in computing
efficiency.
-3/8/23 don't use RDP classifier b/c they only consider LSU and I don'tthink we actually have enough LSU coverage to solely depend on that

Kacey:
-take output FASTA (unaligned) and pass through NCSU ITSx to separate various loci of interest (should be ITS1, 5.8S, ITS2, some of LSU)
-DO NOT retain all metadata for OTU members. (my data showed the same OTU multiple times in the tree)
-ITS locus is included (first FASTA) - filter unknowns to selected taxon and generate UNITE report
-Run RDP with UNITE (ITS), and FunGuild
-Cluster on only one locus
-Cluster at 0.99
-Create OTU fasta files
-RAxML with de novo tree construction


*use result files from run 3HXRGT5G. This is good one.*

T-BAS data:
OTU is the otu name that was input for the isolate name in T-BAS, every isolate has a unique OTU.
Query.sequence is also unique to each isolate. It is the sample number (1-250).

```{r}
geumroot <- read.csv("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archive3HXRGT5G_/assignments_report_addvoucher3HXRGT5G.csv")

colnames(geumroot)[16]<- "otu" 
colnames(geumroot)[1]<- "Query.sequence"
geumroot$Query.sequence <- sprintf("%03d", geumroot$Query.sequence)

```

## Phylogenetic Tree

TBAS tree with all sequences -> 3HXRGT5G.nwk
TBAS tree after selecting all query sequences and pruning the tree -> PM2RLCID.nwk *this is what I want*

Change tip labels to oTU numbers 

```{r}
#newtree <- read.tree("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archive3HXRGT5G_/3HXRGT5G.nwk")

trimmednwk <-read.tree("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archivePM2RLCID_/PM2RLCID.nwk")

# tree with species names 
#trimmednwk$tip.label <- geumroot[[12]][match(trimmednwk$tip.label, geumroot[[1]])]
#taxtree <- ggtree(trimmednwk)+geom_tiplab(size=1)
#ggsave('C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/taxtree.pdf')

# tree with OTUs 
trimmednwk$tip.label <- geumroot[[16]][match(trimmednwk$tip.label, geumroot[[1]])]
#trimmednwk <- ggtree(trimmednwk)+geom_tiplab(size=1)
#ggsave('C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/otutree.pdf')

plot(trimmednwk)

```

# Culture data

There are multiple OTUs for one species, so this is to clean it up

Culture IDs are unique to the sequence. It contains the site, community, and plant individual number.

```{r}
culture <- read_sheet("https://docs.google.com/spreadsheets/d/1Ys3msUUPmmOo1NeRqHfsdhJzU_mEwBOytZe6AmAribQ/edit?gid=0#gid=0", sheet = "Sheet1", na='NULL')

culture2<-culture%>%
  dplyr::select(Query.sequence,...3)%>%
  rename(PlantIndividual=...3)%>%
  separate(PlantIndividual, 
           into = c("Community", "PlantIndividual"), 
           sep = "(?<=[A-Za-z])(?=[0-9])"
           )
head(culture2)

culture2$Query.sequence <- sprintf("%03d", culture2$Query.sequence)

geumroot2<-geumroot%>%
  unite(CultureID,otu,Taxon.assignment,remove=F)%>%
  dplyr::select(Query.sequence,CultureID,Community_Type_3HXRGT5G,Site_3HXRGT5G,Latitude_3HXRGT5G,Longitude_3HXRGT5G,otu,Trophic.Mode,Guild,Taxon.assignment,GenusSpecies)%>%
  rename(Community=Community_Type_3HXRGT5G,Site=Site_3HXRGT5G,Lat=Latitude_3HXRGT5G,Long=Longitude_3HXRGT5G)%>%
mutate(Community = factor(Community, levels = c("DM", "SB", "FF", "MM")),Site = factor(Site, levels = c("P", "Q")))
head(geumroot2)

length(geumroot2$CultureID)

dat<-full_join(geumroot2,culture2,by="Query.sequence")%>%
  filter(is.na(otu)==F)
head(dat)
dim(dat)

#Collapse identical OTUs into one row. Looking at abundances of OTUs in the whole dataset. there are many many 1's (singletons). also this is needed to create the community dataset below
dat2<-dat%>%
  group_by(Community.x,Site,PlantIndividual,otu)%>%
  summarise(abundance=n())
as.data.frame(dat2)
data.frame(dat2$Community.x,dat2$Site,dat2$PlantIndividual,dat2$otu,dat2$abundance)

#make wide
dat3<-dat2%>%
  ungroup()%>%
  unite(CommunitySitePL,Community.x,Site,PlantIndividual,remove=F)%>%
  spread(otu,abundance,fill=0)
dat.comm<-data.frame(dat3[,5:39])
row.names(dat.comm)<-dat3$CommunitySitePL

```

## Faith's Phylogenetic distance

```{r}

PD<-pd(dat.comm,trimmednwk)

dat4<-data.frame(dat3[,1:4],PD,dat3[,5:39])
```

## MPD by CommunitySitePL

```{r}
phydist <- cophenetic(trimmednwk)
ses.mpd.result.notweighted <- ses.mpd(dat.comm, phydist, null.model="taxa.labels",abundance.weighted=FALSE, runs=999) #takes 5 min with 999
ses.mpd.result.notweighted
ses.mpd.result.notweighted$CommunitySitePL<-rownames(ses.mpd.result.notweighted)
ses.mpd.result.notweighted1<-ses.mpd.result.notweighted%>%
  select(CommunitySitePL,mpd.obs.z)%>%
  rename(mpd.obs.z.notweighted=mpd.obs.z)

ses.mpd.result.weighted <- ses.mpd(dat.comm, phydist, null.model="taxa.labels",abundance.weighted=TRUE, runs=999) #takes 5 min with 999
ses.mpd.result.weighted
ses.mpd.result.weighted$CommunitySitePL<-rownames(ses.mpd.result.weighted)
ses.mpd.result.weighted1<-ses.mpd.result.weighted%>%
  select(CommunitySitePL,mpd.obs.z)%>%
  rename(mpd.obs.z.weighted=mpd.obs.z)

dat5<-dat4%>%
  full_join(ses.mpd.result.notweighted1)%>%
  full_join(ses.mpd.result.weighted1)
  
  
dat6<-data.frame(dat5[,1:6],dat5[,42:43],dat5[,7:41])
head(dat6)

```

## Phyloseq Object

```{r}
otus<-dat6[,9:43]
otus2<-t(otus)
sampleotus<-dat6[,c(1:8)]
taxonomyotus<-as.matrix(data.frame(Kingdom=row.names(otus2),Phylum=row.names(otus2),Class=row.names(otus2),Order=row.names(otus2),Class=row.names(otus2),Family=row.names(otus2),Genus=row.names(otus2),Species=row.names(otus2)))
rownames(taxonomyotus)<-row.names(otus2)

datp <- merge_phyloseq(otu_table(otus2,taxa_are_rows = T), tax_table(taxonomyotus), sample_data(sampleotus),trimmednwk)

#calculate unifrac distances
unifracp<-unifrac(otus,trimmednwk)
```

# Testing Blasting to UNITE

Make sure to get the most recently updated reference file from the UNITE database website.
https://doi.plutof.ut.ee/doi/10.15156/BIO/2959333
At teh bottom under downloads

taxaonly2 <- read.csv("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/taxaonly.csv")

```{r}
unite.ref <- "C:/Users/Kacey/Documents/Tulane/Lab/Culture/UNITE/sh_general_release_dynamic_s_04.04.2024.fasta"


#I got this data from assignments_report_nodupsM76GMYAB
myotus<-read.csv("C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/T-BAS_Results/tbas21_archive3HXRGT5G_/assignments_report_nodups3HXRGT5G.csv",header=T);rownames(myotus)<-myotus$abundance

myotus$Query.sequence <- sprintf("%03d", myotus$Query.sequence)

myotus2 <- myotus[,c(21,16)]
names(myotus2)[names(myotus2) == 'ITS'] <- 'sequence'
names(myotus2)[names(myotus2) == 'otu'] <- 'abundance'

taxa<-assignTaxonomy(myotus2, unite.ref, multithread = TRUE, minBoot=70, tryRC = TRUE,outputBootstraps=T) #was minBoot=70
taxaonly<-data.frame(taxa$tax);rownames(taxaonly)<-1:dim(taxa$tax)[1]
taxaboot<-data.frame(taxa$boot);rownames(taxaboot)<-1:dim(taxa$tax)[1]
taxaonly
taxaboot
rownames(taxaonly)<-rownames(myotus)
genusspecies<-data.frame(otu=rownames(myotus),genusspecies=paste(gsub("^.*?__","",taxaonly[,"Genus"]),gsub("^.*?__","",taxaonly[,"Species"])),genusboot=taxaboot[,"Genus"],speciesboot=taxaboot[,"Species"])

sort(unique(genusspecies$genusspecies))
sort(unique(taxaonly$Phylum))

taxaonly%>%group_by(Phylum)%>%tally()
```

## FunGuild

The weird thing about FUNGuildR is that for some taxa, like when I have Fusarium equiseti it matches to Nectriaceae rather than Fusarium in the database. When I used the FUNGUILD in the terminal, it worked better and matched to the lowest taxonomic level. 

using FUNGuildR

```{r}
# genussp<-paste(gsub("^.*?__","",taxaonly$Genus),gsub("^.*?__","",taxaonly$Species))
# taxaonly$Taxonomy<-paste(gsub("^.*?__","",taxaonly$Kingdom),gsub("^.*?__","",taxaonly$Phylum),gsub("^.*?__","",taxaonly$Class),gsub("^.*?__","",taxaonly$Order),gsub("^.*?__","",taxaonly$Family),gsub("^.*?__","",taxaonly$Genus),genussp,sep=";")

#Download the up-to-date database
#fung <- get_funguild_db()

#save it to my computer for reproducable data
#saveRDS(fung, "funguild.rds")

#load it back into workspace
#fung <- loadRDS("funguild.rds")

# fung_guilds <- funguild_assign(taxaonly, db = fung)

#temp3 <- funguild_query("Buergenerula*", "taxon", db = fung)


#Doing it in terminal - use this
taxaonly2<-taxaonly
taxaonly2$taxonomy<-paste(taxaonly2$Kingdom,taxaonly2$Phylum,taxaonly2$Class,taxaonly2$Order,taxaonly2$Family,taxaonly2$Genus,taxaonly2$Species,sep=";")

write.csv(taxaonly2,"C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/taxaonly.csv")

#open the file, make the first column name OTU ID, save as a .txt file (add the .txt extension). then run below:

python FUNGuild.py taxa -otu taxaonly.txt -format tsv -column taxonomy -classifier unite
python FUNGuild.py guild -taxa taxaonly.taxa.txt         

taxaonly3<-data.frame(myotus2[,2],taxaonly2[,2:9])
colnames(taxaonly3)[1] <- "OTU"
colnames(taxaonly3)[9] <- "Taxonomy"
#taxaonly3$OTU <- stringr::str_replace(taxaonly3$OTU, '\\OTU', '')

guilds <- funguild_assign(taxaonly3)

#guilds<-read.delim("/Users/farrer/Dropbox/EmilyComputerBackup/Documents/LAmarsh/Culturing/FiguresStats/LAmarshCulture/FUNGuild/taxaonly.taxa.guilds.txt")
View(guilds)

guilds%>%filter(trophicMode==("Pathotroph"))
guilds%>%filter(trophicMode==("Symbiotroph"))

View(funguild_query("*Saprotroph*", "trophicMode", db = guilds))

#merge with OTU table (of datp) with guilds from above
otutomerge<-data.frame(otu_table(datp))
otutomerge$OTU<-rownames(otutomerge)
head(guilds)
guilds2<-guilds%>%
  full_join(otutomerge)
head(guilds2)
ind<-which(guilds2$guild=="Plant Pathogen")
plantpathogen<-colSums(guilds2[ind,21:64])
plantpathogentaxa<-colSums(guilds2[ind,21:64]>0)

ind<-funguild_query("*Plant Pathogen*", "guild", db = guilds2)$OTU#trophicMode
ind2<-which(guilds2$OTU%in%ind)
plantpathogenbroad<-colSums(guilds2[ind2,21:64])
plantpathogenbroadtaxa<-colSums(guilds2[ind2,21:64]>0)

ind<-funguild_query("*Plant Pathogen*", "guild", db = guilds2)#trophicMode
ind2<-ind[which(ind$confidenceRanking%in%c("Probable","Highly Probable")),"OTU"]
ind3<-which(guilds2$OTU%in%ind2)
plantpathogenbroadprobablehp<-colSums(guilds2[ind3,21:64])
plantpathogenbroadprobablehptaxa<-colSums(guilds2[ind3,21:64]>0)

ind<-funguild_query("*Symbiotroph*", "trophicMode", db = guilds2)$OTU
ind2<-which(guilds2$OTU%in%ind)
symbiotroph<-colSums(guilds2[ind2,21:64])
symbiotrophtaxa<-colSums(guilds2[ind2,21:64]>0)

ind<-funguild_query("*Symbiotroph*", "trophicMode", db = guilds2)
ind2<-ind[which(ind$confidenceRanking%in%c("Probable","Highly Probable")),"OTU"]
ind3<-which(guilds2$OTU%in%ind2)
symbiotrophprobablehp<-colSums(guilds2[ind3,21:64])
symbiotrophprobablehptaxa<-colSums(guilds2[ind3,21:64]>0)

totalabundance<-colSums(guilds2[,21:64])

temp<-data.frame(sample_data(datp))
temp$rownames<-rownames(temp)
temp<-temp%>%
  dplyr::select(rownames,CommunitySitePL)
temp2<-data.frame(temp,plantpathogen,plantpathogenbroad,plantpathogenbroadprobablehp,symbiotroph,symbiotrophprobablehp,totalabundance,plantpathogentaxa,plantpathogenbroadtaxa,plantpathogenbroadprobablehptaxa,symbiotrophtaxa,symbiotrophprobablehptaxa)

dat7<-dat6%>%
  full_join(temp2)

write.csv(dat7,"C:/Users/Kacey/Documents/Tulane/Lab/Culture/Geum roots/GeumMastersheet.csv")

#phragspartina<-dat6%>%
  #filter(HostPlant%in%c('Phragmites australis','Spartina patens'))
#phragspartina<-dat7%>%
  #filter(HostPlant%in%c('P. australis','S. patens'))
```

# Summary of files

```{r}
datp #phyloseq object
head(dat6) #big data frame, wide data format, dat3 plus PD and MPD data
dat7 #dat6 plus funguild pathogens/symbiotrophs
dat2 #long dataformat 
```

# git hub token stuff

```{r}
install.packages("gitcreds")
library(gitcreds)
gitcreds_set()
 #first when it asks to enter password or token I put my computer password
 #then do gitcreds_set() again and select 2, then paste my token
#Note: use usename (email) and token, when RStudio wants the github password
```